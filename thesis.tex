\documentclass{report}
\usepackage[utf8]{inputenc}
\usepackage{amsmath, amssymb}
\usepackage{amsthm, thmtools}
\usepackage{etoolbox}  % for hooking into environments
\usepackage[shortlabels]{enumitem}
\usepackage[parboxrestore]{marginnote}
\usepackage{mathtools}
\usepackage{changepage}
\usepackage{cancel}
\usepackage{faktor}
\usepackage[protrusion=true,expansion=true]{microtype}	
\usepackage{float}
\usepackage[dvipsnames]{xcolor}
\usepackage{url}
\usepackage{nameref}
\usepackage{xspace}
\usepackage{dsfont} % need it for \mathbb{1}
\usepackage{dirtytalk}
\usepackage[parfill]{parskip} % do not indent new paragraphs
\usepackage[linktoc=all]{hyperref}
% \usepackage{cleveref}
\usepackage{tocloft}
\setlength{\cftbeforechapskip}{1pt}
\renewcommand{\cftchapdotsep}{\cftdotsep}   % chapters use dots too

\newcommand{\remarkautorefname}{Remark}

\hypersetup{
  linktoc=section,      % Only the number in the ToC is a link
  colorlinks=true,
  linkcolor=Blue,        % or any color you want
  citecolor=Green,
}

% \usepackage[a4paper, top=2.5cm, bottom=3cm, left=3cm, right=2.5cm, portrait]{geometry}
\usepackage{geometry}
\geometry{a4paper, portrait
%, margin=1.0in
}

% TEMPLATE STUFF
\usepackage{fancyhdr}

\usepackage{titlesec}
\titleformat{\chapter}{\normalfont\scshape\Large}{\Large\Roman{chapter}.}{10pt}{\Large}
\titlespacing*{\chapter}{0pt}{5.5ex plus 1ex minus .2ex}{1.3ex plus .2ex}
\titleclass{\chapter}{straight}

\titleformat{\section}
  {\normalfont\bfseries\large}
  {\thesection}{1em}{}


\usepackage[
    backend=biber,
    style=alphabetic,
    sorting=ynt
]{biblatex}
\addbibresource{references.bib}

\makeatletter
\renewcommand*\env@matrix[1][\arraystretch]{%
  \edef\arraystretch{#1}%
  \hskip -\arraycolsep
  \let\@ifnextchar\new@ifnextchar
  \array{*\c@MaxMatrixCols c}}
\makeatother

\newcommand{\FF}{\mathbb{F}}
\newcommand{\ZZ}{\mathbb{Z}}
\newcommand{\NN}{\mathbb{N}}
\newcommand{\NO}{{\mathbb{N}_0}}
\newcommand{\NP}{\mathbb{N}_+}
\newcommand{\PP}{\mathbb{P}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\QQ}{\mathbb{Q}}
\newcommand{\CC}{\mathbb{C}}
\newcommand{\KK}{\mathbb{K}}
\newcommand{\TT}{\mathbb{T}}

\DeclarePairedDelimiter\abs{\lvert}{\rvert} %NOTE: \abs* gives auto-sizing
\DeclarePairedDelimiter\norm{\lVert}{\rVert}%
% \DeclarePairedDelimiter\norm\lVert\rVert
\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}

% \DeclareMathOperator{\Var}{Var}
\newcommand{\Var}[1]{\operatorname{Var}\left(#1\right)}
\newcommand{\Exp}[1]{\mathbb{E}\left[#1\right]}
\newcommand{\CondExp}[2]{\mathbb{E}\left[#1 \mid #2\right]}
\newcommand{\DefEmph}[1]{\textbf{#1}} 
\newcommand{\Cov}[2]{\operatorname{Cov}\left(#1, #2\right)} 
\newcommand{\Corr}[2]{\operatorname{Corr}\left(#1, #2\right)}
\newcommand{\CharFunction}[1]{\mathds{1}_{#1}}
\newcommand{\Restrict}[2]{\left. #1 \right|_{#2}}
\newcommand{\ScalarProd}[2]{\left\langle #1, #2 \right\rangle}
\newcommand{\Placeholder}{\,\mathrel{\cdot}\,}
\DeclareMathOperator{\ProjOp}{\mathbf{P}}
\newcommand{\Convolve}[3][]{#2 \star_{#1} #3}
\newcommand{\Closure}[1]{\overline{#1}}
\newcommand{\Bracket}[1]{\left[#1\right]}

\DeclareMathOperator{\DConv}{\stackrel{(d)}{\longrightarrow}}
\DeclareMathOperator{\PConv}{\stackrel{\PP}{\longrightarrow}}
\DeclareMathOperator{\DEquiv}{\stackrel{(d)}{=}}
\DeclareMathOperator{\DefiningEquality}{\coloneqq}
\DeclareMathOperator{\DefiningEqualityRev}{\eqqcolon}
\DeclareMathOperator{\Union}{\cup}
\DeclareMathOperator{\DisUnion}{\dot{\cup}}
\DeclareMathOperator{\Intersection}{\cap}
\DeclareMathOperator{\Range}{ran}
\DeclareMathOperator{\Support}{supp}
\DeclareMathOperator{\Ext}{Ext}



% \DeclareMathOperator{\dist}{dist}
% \DeclareMathOperator{\weight}{weight}

\swapnumbers % optional, of course
\newtheorem{theorem}{Theorem}[chapter]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\renewenvironment{proof}{{\bf \emph{Proof (idea):} }}{\hfill $\Box$ \\} 
% \newenvironment{proofsketch}{%
%   \renewcommand{\proofname}{Proof (sketch)}\proof}{\endproof}

\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

\AtBeginEnvironment{remark}{
  \pushQED{\qed}\renewcommand{\qedsymbol}{$\lrcorner$}%
}
\AtEndEnvironment{remark}{\popQED}


\AtBeginEnvironment{example}{%
  \pushQED{\qed}\renewcommand{\qedsymbol}{$\scriptstyle\triangle$}%
}
\AtEndEnvironment{example}{\popQED}

\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{example}{Example}[section]


\newcommand{\thistheoremname}{}

\newtheorem{genericthm}[theorem]{\thistheoremname}
\newenvironment{namedthm}[1]
  {\renewcommand{\thistheoremname}{#1}%
   \begin{genericthm}}
  {\end{genericthm}}


\DeclareRobustCommand{\rchi}{{\mathpalette\irchi\relax}}
\newcommand{\irchi}[2]{\raisebox{\depth}{$#1\chi$}} % inner command, used by \rchi
\newcommand{\iid}{\text{i.i.d}\xspace}
\newcommand{\TODO}[1]{\text{\textcolor{red}{TODO: #1}}\xspace}

\let\oldphi\phi
\let\phi\varphi

\let\oldrho\rho
\let\rho\varrho

\let\oldepsilon\epsilon
\let\epsilon\varepsilon

\renewcommand{\chapterautorefname}{Chapter}
\renewcommand{\sectionautorefname}{Section}
\renewcommand{\subsectionautorefname}{Subsection}
\renewcommand{\subsubsectionautorefname}{Subsubsection}
\renewcommand{\figureautorefname}{Figure}
\renewcommand{\tableautorefname}{Table}
\renewcommand*{\equationautorefname}{\!} % effectively hides "Equation"
\newcommand{\fullref}[1]{\autoref{#1}~(\nameref{#1})}

\newcommand{\bigO}[1]{\ensuremath{\mathop{}\mathopen{}\mathcal{O}\mathopen{}\left(#1\right)}}

\newcommand\smallO[1]{
    \mathchoice
    {% mode \displaystyle
      \scriptstyle\mathcal{O}\left(#1\right)
    }
    {% mode \textstyle
      \scriptstyle\mathcal{O}\left(#1\right)
    }
    {% mode \scriptstyle
      \scriptscriptstyle\mathcal{O}\left(#1\right)
    }
    {% mode \scriptscriptstyle
      \scalebox{0.8}{$\scriptscriptstyle\mathcal{O}$}\left(#1\right)
    }
}


\title{\textsc{Convergence of the Two-Dimensional Dynamic Ising-Kac Model to $\Phi^4_2$}
\\[1.5em]
{\small {for}}\\[1.5em]
{\Large \textsc{Stochastic Partial Differential Equations: \\Classical and New}}\\
{\large (Dr. Guilherme de Lima Feltes)}}

\author{
    \textsc{Balázs Kossovics}\\
    {\small (Matr. 5563286)}
}
\date{2025 Summer Semester}


\begin{document}

\begin{center}
    \Large{{\textsc{Course Report for Stochastics IV.}}}\\[1em]
    \normalsize
    Balázs Kossovics \\[0.25em]
    % Convergence of the Two-Dimensional Dynamic Ising–Kac Model to $\Phi^4_2$\\[0.5em]
    % Summer Semester 2025
\end{center}

\vspace{1em}
\noindent\textbf{Abstract.} In this report we present a summary of \textit{Convergence of the Two-Dimensional Dynamic Ising-Kac Model to $\Phi^4_2$} from Jean-Christophe Mourrat and Hendrik Weber, whose convergence result gives a physical interpretation to the need for renormalization in the $\Phi^4_2$ equation. We first introduce the Ising-Kac model and set up an evolution equation for the discrete system, then briefly recall the solution theory of the $\Phi^4_2$ equation, and state the main convergence result of the paper. In the remainder we outline its proof, first focusing on the linearized system (bounds, tightness and convergence), and later using these results to give a sketch of the convergence of the non-linear equation.
% \vspace{1.5em}

\tableofcontents

\chapter{Introducion}
The Ising model is a stochastic model of ferromagnetism. On the microscopic level we consider a discrete system of interacting particles on the $\Lambda_N = \ZZ^2 / (2N+1)\ZZ^2$ grid for some $N \in \NN$ (which we identify with $\left\{-N, \dots, N\right\}^2$), where in every grid point sits a spin with exactly two possible state: $\pm1$ (intuitively: the spin pointing in the direction of either the north or the south). The set of corresponding spin configurations will be denoted by $\Sigma_N = \left\{-1, 1\right\}^{\Lambda_N}$. In the standard Ising model the particles are interacting only with their immediate neighbours, while in the Ising-Kac model the particles can influence the behaviour of the other particles in a small radius proportional to a scaling factor $\gamma > 0$. To build intuition about the behaviour of the system, we can imagine to have a probability distribution on $\Sigma_N$, which also depends on the inverse temperature $\beta > 0$. Under this distribution, configurations with close-by spins aligned in the same direction are more probable, than configurations with completely disorganised spins. The system is more likely to go from a less probable configuration to a more probable one, but the reverse transition is also not excluded, especially at low inverse temperatures. The locally averaged field describes the strength of the field at each gridpoint, and we will be interested in the fluctuations of this field after suitable renormalization and continuous extension to $\TT^2$. In particular one can show that this random process describing the fluctuations of the field converges in law to the solution of the $\Phi^4_2$ equation 
\begin{align}
  \label{eq:phi_4_2}
  \begin{split}
  \partial_t X(t, x) &= \Delta X(t, x) - \frac{1}{3}X^3(t, x) + A X(t, x) + \sqrt{2}\xi(t, x)\\
  X(0, \cdot) &= X^0\,    
  \end{split}
\end{align}
as $\gamma \to 0$, as long as the initial configurations $X_\gamma^0$ of the discrete system converges in law to $X^0$.

We know, that the solution of this equation is distribution valued, and from the mild formulation of the equation it follows that $X_t \in \mathcal{C}^- \DefiningEquality \Union_{\nu > 0} \mathcal{C}^{-\nu}$, which makes the $X^3(t, \Placeholder)$ term in the equation undefined. In the solution theory of the $\Phi^4_2$ equation this is corrected by renormalizing the equation with a diverging linear term, formally written as 
\begin{align}
  \partial_t X(t, x) = \Delta X(t, x) - \frac{1}{3}\left(X^3(t, x) - 3 \infty \times X(t, x)\right) + A X(t, x) + \sqrt{2}\xi(t, x)\,.
\end{align}
We will see in the following, that the need for renormalization is not simply a mathematical artifact of the solution theory, but consistent with the physical interpretation, in the sense that the renormalization represents \say{a shift of the critical temperature away from its mean field value} \cite{mourrat2015convergencetwodimensionaldynamicisingkac}.

\section{The Ising-Kac model}
In order to precisely describe the interaction, we choose an arbitrary kernel $\mathfrak{K}: \RR^2 \to [0, 1]$ satisfying $\mathfrak{K} \in \mathcal{C}^2(\RR^2)$, $\Support{\mathfrak{K}} \subset B^2(0, 3) \DefiningEquality \left\{x \in \RR^2 \colon \abs{x} < 3\right\}$, invariant under rotations and having furthermore $$\int_{\RR^2} \mathfrak{K}(x) dx = 1\,,\quad \int_{\RR^2} \mathfrak{K}(x) \abs{x}^2 dx = 4\,.$$


For a scaling factor $0 < \gamma < \frac{1}{3}$ and $N = N(\gamma) \gg \gamma^{-1}$, we discretize the kernel as 
$$\kappa_\gamma: \Lambda_N \to [0, 1]\,,\quad\kappa_\gamma(k) = \begin{cases}
  \frac{\mathfrak{K}(\gamma k)}{\sum_{l \in \Lambda_N} \mathfrak{K}(\gamma l)}&k \neq 0\\
  0 & k = 0
\end{cases}\,,$$
which acts as a mollifier on the grid to define the locally averaged field for any $\sigma \in \Sigma_N$ configuration by a discrete convolution
\begin{align}
  h_\gamma(\sigma, k) \DefiningEquality (\Convolve{\kappa_\gamma}{\sigma})(k) \DefiningEquality  \sum_{l\in \Lambda_N} \kappa_\gamma(k-l) \sigma(l)\,,
\end{align}
where the addition operation is always understood modulo $2N + 1$ on the grid: $k + l \DefiningEquality k + l + n(2N + 1) \in \left\{-N, \ldots, N\right\}$ for appropriate $n \in \ZZ$. 

The locally averaged field $h_\gamma$ describes the strength of the magnetic field for a spin at position $k$, and the total energy of the system is defined through the Hamiltonian \begin{align}
  \mathcal{H}_\gamma(\sigma) \DefiningEquality -\frac{1}{2}\sum_{k\in \Lambda_N} \sigma(k) h_\gamma(k)\,.
\end{align} With the help of the Hamiltonian we can define the Gibbs measure on $\Sigma_N$ for any $\beta > 0$ inverse temperature as \begin{align}
  \lambda_\gamma(\sigma) = \frac{1}{\mathcal{Z}_\gamma}\exp{\left(-\beta \mathcal{H}_\gamma(\sigma)\right)}\,,\quad \mathcal{Z}_\gamma = \sum_{\sigma \in \Sigma_N} \exp{\left(-\beta \mathcal{H}_\gamma(\sigma)\right)}\,.
\end{align}

To describe the evolution of the process we define a Markov process on $\Sigma_N$ given by its infinitesimal generator \begin{align}
  \mathcal{L}_\gamma(f)(k) = \sum_{l \in \Lambda_N} c_\gamma(\sigma, l)(f(\sigma^j) - f(\sigma))
\end{align}
for any function $f: \Lambda_N \to \RR$, where by $\sigma^j \in \Sigma_N$ we denote a configuration identical to $\sigma$, except for the spin at position $j$, which is flipped. For the jump rates $c_\gamma(\sigma, l)$, we choose the those of the Glauber dynamics, which are defined and can be simplified as
\begin{align}
  \label{eq:trig_jump_rates}
  c_\gamma(\sigma, l) = \frac{\lambda(\sigma^l)}{\lambda(\sigma) + \lambda(\sigma^l)} = \frac{e^{-\sigma(j)\beta h_\gamma(\sigma, j)}}{e^{\beta h_\gamma(\sigma, j)} + e^{-\beta h_\gamma(\sigma, j)}} = \frac{1}{2}\left(1 - \sigma(j) \tanh\left(\beta h_\gamma(\sigma, j)\right)\right)\,,
\end{align}
where we used that $h_\gamma(\sigma, j)$ does not depend on $\sigma(j)$ and $\sigma(j) \in \left\{-1, 1\right\}$.

For the Markov process generated by the semigroup we write $(\sigma(t))_{t \ge 0}$, and for the corresponding process generated by the observable $h_\gamma(\cdot, k)$ we write $(h_\gamma(t, k))_{t \ge 0} \DefiningEquality h_\gamma(\sigma(t), k)$ for each $k \in \Lambda_N$, for which we can write the evolution equation
\begin{align}
  \label{eq:microscopic_evolution_equation}
  h_\gamma(t, k) = h_\gamma(0, k) + \int_{0}^{t} \mathcal{L}_\gamma h(s, k) \,ds + m_\gamma(t, k)\,,
\end{align}
where $(m(t, k))_{t\ge 0}$ is a martingale for each $k\in \Lambda_N$\cite[Appendix B]{mourrat2015convergencetwodimensionaldynamicisingkac}, since the $\sigma(\cdot, k)$ process is a Feller process \cite[Section 6.5.1]{gall2016brownian}. Using the trigonometric representation of the jump rates \eqref{eq:microscopic_evolution_equation}, the Taylor expansion $\tanh(h) = h - \frac{h^3}{3} + o(h^6)$ and the fact, that $h_\gamma(\sigma^j, k) - h_\gamma(\sigma, k) = -2 \kappa_\gamma(k-j) \sigma(j)$ we obtain 
\begin{align*}
  \begin{split}
    \mathcal{L}_\gamma h_\gamma(\sigma, k) &= \left(\Convolve{\kappa_\gamma}{h_\gamma(\sigma, k)} - h_\gamma(\sigma, k)\right) + (\beta - 1) \Convolve{\kappa_\gamma}{h_\gamma(\sigma, k)} - \frac{\beta^3}{3}\left(\Convolve{\kappa_\gamma}{h_\gamma^3(\sigma, k)}\right) + \operatorname{err}\\
  &\DefiningEqualityRev \bar{\Delta}_\gamma h_\gamma(\sigma, k) + (\beta - 1) \Convolve{\kappa_\gamma}{h_\gamma(\sigma, k)} - \frac{\beta^3}{3}\left(\Convolve{\kappa_\gamma}{h_\gamma^3(\sigma, k)}\right) + \operatorname{err}\,.
  \end{split}
\end{align*}
We use the evolution equation \eqref{eq:microscopic_evolution_equation} to derive an SPDE after suitable rescaling on $\TT^2$ (which we identify with $[0, 1]^2$). For this purpose we choose $\gamma \in (0, 1)$, $N = N(\gamma)$ (to be defined later), $\epsilon = \frac{2}{2N + 1}$ and $\alpha, \delta > 0$ scaling factors, and we assign to every $k \in \Lambda_N$ the macroscopic coordinates by scaling $$k = (k_1, k_2) \mapsto \epsilon k =(\epsilon k_1, \epsilon k_2) \in \TT^2\,.$$ Let us in particular denote $\Lambda_\epsilon = \epsilon \Lambda_N$, and for these points we consider the rescaled field
\begin{align}
  X_\gamma(t, x) = \frac{1}{\delta}h_\gamma\left(\frac{t}{\alpha}, \frac{x}{\epsilon}\right)~(x\in \Lambda_\epsilon, t \ge 0)\,.
\end{align}
From the evolution equation \eqref{eq:microscopic_evolution_equation} after rescaling we get
\begin{align}
  \label{eq:evolution_in_macroscopic_coordintes}
  \begin{split}
      X_\gamma(t, x) =& X_\gamma(0, x) + \int_{0}^{t} \biggl(\frac{\epsilon^2}{\gamma^2 \alpha}\tilde{\Delta}_\gamma X_\gamma(s, x) + \frac{\beta - 1}{\alpha} \Convolve[\epsilon]{K_\gamma}{X_\gamma(s, x)}\\
    &-\frac{\beta^3}{3} \frac{\delta^2}{\alpha} \Convolve[\epsilon]{K_\gamma}{X_\gamma^3(s, x)} + \Convolve[\epsilon]{K_\gamma}{E_\gamma(s, x)}\biggr)\,ds + M_\gamma(t, x)\,,
  \end{split}
\end{align}
where $K_\gamma(x) = \epsilon^{-2} \kappa_\gamma(\epsilon^{-1}x) = c_\gamma \frac{\gamma^2}{\epsilon^2}\mathfrak{K}\left(\frac{\gamma}{\epsilon}x\right)$ is our rescaled kernel, $M_\gamma(t, x) \DefiningEquality \frac{1}{\delta}m_\gamma\left(\frac{t}{\alpha},\frac{x}{\epsilon}\right)$ is the rescaled martingale, $\tilde{\Delta}_\gamma = \frac{\gamma^2}{\epsilon^2} \bar{\Delta}_\gamma$ is the rescaled discrete Laplacian and $\Convolve[\epsilon]{}{}$ is the discrete convolution on $\Lambda_\epsilon$. The error term $E_\gamma(s, x)$ is furthermore given explicitely as 
\begin{align}
  \label{eq:error_term}
  E_\gamma(t, \cdot) = \frac{1}{\delta \alpha}\left(\tanh\left(\beta \delta X_\gamma(t, \cdot)\right) - \beta \delta X_\gamma(t, \cdot) + \frac{(\beta \delta)^3}{3} X_\gamma(t, \cdot)^3\right)\,.
\end{align}
To fix the above appearing scaling factors as a function of the Kac scaling parameter $\gamma$, we have to observe the following constraints 
\begin{itemize}
  \item $N = \floor{\lambda^{-2}}$,
  \item  $\epsilon = \frac{2}{2N + 1}$ (which is by definition the distance between adjacent particles in macroscopic coordinates),
  \item $1 \approx \frac{\epsilon^2}{\gamma^2 \alpha} \approx \frac{\delta^2}{\alpha}$ (so that the corresponding terms in \eqref{eq:evolution_in_macroscopic_coordintes} converge to something non-trivial as $\gamma \to 0^+$),
\end{itemize}
which results in $\alpha = \gamma^2, \delta=\gamma$. In partcular, the leading order term in the expansion of the error \eqref{eq:error_term} scales as $\frac{(\beta \delta)^5}{\delta\alpha} = \beta^5 \gamma^2$, which we would expect to converge to $0$ for an appropriate choice of $\beta$, whose value is not yet determined. Based on \eqref{eq:evolution_in_macroscopic_coordintes} a seemingly reasonable choice could be $\frac{\beta - 1}{\alpha} \approx 1$, which turns out to be not the right one. We instead assume $(\beta - 1) = \alpha(\mathfrak{c}_\gamma + A)$ for some $A \in \RR$ fixed and we set \begin{align}
  \label{eq:mathfrak}
  \mathfrak{c}_\gamma = \frac{1}{4}\sum_{\substack{k \in \left\{-N, \ldots, N\right\}^2\\k\neq 0}}\frac{\abs{\hat{K}_\gamma(k)}^2}{\gamma^{-2} (1 - \hat{K}_\gamma(k))}\,.
\end{align}
We will furthermore write $\Delta_\gamma = \frac{\epsilon^2}{\gamma^2}\frac{1}{\alpha}\tilde{\Delta}_\gamma$. With these parameters set, the evolution equation reads as
\begin{align}
  \label{eq:evolution_in_macroscopic_coordintes_fixed}
  \begin{split}
      X_\gamma(t, x) =& X_\gamma(0, x) + \int_{0}^{t} \biggl({\Delta}_\gamma X_\gamma(s, x) + (\mathfrak{c}_\gamma + A) \Convolve[\epsilon]{K_\gamma}{X_\gamma(s, x)}\\
    &-\frac{\beta^3}{3} \Convolve[\epsilon]{K_\gamma}{X_\gamma^3(s, x)} + \Convolve[\epsilon]{K_\gamma}{E_\gamma(s, x)}\biggr)\,ds + M_\gamma(t, x)\,.
  \end{split}
\end{align}
$X_\gamma(t, \cdot)$ was so far defined only for the points $x \in \Lambda_\epsilon$, thus if we wanted to talk about its convergence to $X$, we have to first extend it to the whole $\TT^2$. For the sake of convenience we do it with the help of trigonometric polynomials, since they play well with the tools of Fourier analysis, but the choice is essentially irrelevant \cite{mourrat2015convergencetwodimensionaldynamicisingkac}. Thus for any $Y: \Lambda_\epsilon \to \RR$ we define the discrete Fourier transform $\hat{Y}$ as \begin{align}
  \hat{Y}(k) = \begin{cases}
      \sum_{x \in \Lambda_\epsilon} \epsilon^2 e^{- i \pi k \cdot x} Y(x)&k \in \left\{-N, \ldots, N\right\}^2\\
      0&\text{otherwise}
  \end{cases}\,,
\end{align}
form which we get by inverse Fourier transformation $$\Ext Y(x) \DefiningEquality \frac{1}{4} \sum_{k \in \ZZ^2} \hat{Y}(k) e^{i \pi k \cdot x} = \frac{1}{4} \sum_{k \in \left\{-N, \dots, N\right\}^2} \sum_{y \in \Lambda_\epsilon}\epsilon^2 e^{i \pi k \cdot (x -y)} Y(y)\,.$$
The extension $\Ext Y$ is smooth, real valued, and it is the unique trigonometric polynomial of degree $N$ coinciding with $Y$ on $\Lambda_\epsilon$. If there is no confusion, we simply write $Y$ for the continuous extension instead of $\Ext{Y}$, and with one notable exception mentioned later, we always use the $\Ext$ operator to continuously extend $\Lambda_\epsilon \to \RR$ functions to $\TT^2 \to \RR$. The extension works identically for functions on a grid of a higher dimensional torus, and the following lemma let us bound the extension uniformly on $\TT^n$ by a uniform bound on $\Lambda_\epsilon$:

\begin{lemma}[{\cite[Lemma A.6]{mourrat2015convergencetwodimensionaldynamicisingkac}}]
  \label{lemma:A6}
  For $N \in \NN$, set $\epsilon = \frac{2}{2N + 1}$ and let $$\Lambda_\epsilon = \left\{x \in \epsilon \ZZ^n: -1 < x_i < 1 \text{ for } i = 1, \ldots, n\right\}\,.$$ For any $Z: \Lambda_\epsilon \to \RR$ we define the extension\begin{align*}
    \Ext{Z}(x) = \sum_{z \in \Lambda_\epsilon}\frac{\epsilon^n}{2^n}Z(z) \prod_{j=1}^n \frac{\sin\left(\frac{\pi}{2}(2N + 1)(x_j - z_j)\right)}{\sin(\frac{\pi}{2}(x_j - z_j))}\,,
  \end{align*}
  defined for all $x \in \TT^n$. Then for any $\kappa > 0$, there exists a constant $C = C(\kappa, n)$ such that
  \begin{align*}
    \norm{\Ext{Z}}_{L^\infty(\TT^n)} \le C \epsilon^{-\kappa} \norm{Z}_{L^\infty(\Lambda_\epsilon)}\,.
  \end{align*}
\end{lemma}
We can now state the main result of the paper

\begin{theorem}
  Assume that the scaling assumptions hold, and the evolution equation of the Ising-Kac model reads as in \eqref{eq:evolution_in_macroscopic_coordintes_fixed}, with the precise value of $\mathfrak{c}_\gamma$ given by \eqref{eq:mathfrak}. Assume also, that $X^0_\gamma$ converges to $X^0$ in $\mathcal{C}^{-\nu}$ for $\nu > 0$ small enough and that $X^0, x^0_\gamma$ are uniformly bounded in $\mathcal{C}^{-\nu + \kappa}$ for an arbitrarily small $\kappa > 0$. Then $X_\gamma$ converges in law to $X$ with respect to $\mathcal{D}(\RR_+, \mathcal{C}^{-\nu})$, the space of $\mathcal{C}^{-\nu}$-valued càdlàg functions on $\RR_+$ endowed with the Skorokhod topology.
\end{theorem}
% \section{Main result}
% Consider 
%   \begin{itemize}
%     \item $\mathcal{D}(\mathbb{R}_+, \mathcal{S})$: $\mathcal{S}$ metric space-valued càdlàg functions on $\mathbb{R}_+$ endowed with the Skorokhod topology
%     \item $\mathcal{C}^{-\nu}~(\nu > 0)$ Besov space, with the def Perkowski used!
%   \end{itemize}

\chapter{Solution theory of $\Phi^4_2$}
\label{chapter:solution_theory_of_phi_4_2}
If we considered the mild formulation 
\begin{align}
  X_t = P_t X_0 + \int_{0}^{t}P_{t-s}\left(-\frac{1}{3}X^3(s) + A X(s)\right)\,ds + \int_0^t P_{t-s} \xi(s) \,ds
\end{align}
of the $\Phi^4_2$ equation, then from the $0^-$ regularity of the stochastic convolution $Z(t) = \int_0^t P_{t-s} \xi(s) \,ds$ we cannot expect the solution $X_t$ to have a better regularity than $Z_t$ itself, making the $X^3_s$ distributional product undefined. One could try working around the issue by spatially localizing the stochastic convolution and to take $\epsilon \to 0$ in $Z_\epsilon(t) = \mathcal{F}_{\TT^2}^{-1}(\phi_\epsilon \mathcal{F}_{\TT^2}(t, \Placeholder))$ where $\phi_\epsilon = \CharFunction{B(0, \epsilon^{-1})}$, for example. It has been shown in \cite{hairer2012triviality}, that under such an approximation the solution $X_\epsilon$ converges to the constant $0$ distribution.

In order to avoid a non-trivial limit of $X_\epsilon$ as $\epsilon \to 0$, one has to introduce a shift of $$\mathfrak{c}_\epsilon = \sum_{0 < \abs{k} < \epsilon^{-1}} \frac{1}{4 \pi^2 \abs{k}^2}$$ in
\begin{align}
  X_\epsilon(t) = P_t X_0 + \int_{0}^{t}P_{t-s}\left(-\frac{1}{3}\left(X^3_\epsilon(s) - \mathfrak{c}_\epsilon X_\epsilon\right)+ A X(s)\right)\,ds + \int_0^t P_{t-s} \xi(s) \,ds\,.
\end{align}
To make this precise, we decompose first $X_t$ as $X_t = Z_t + v_t$, and notice that $v_t$ now solves the 
\begin{align}
  \label{eq:phi_eq_in_v}
  \begin{split}
    \partial_t v &= \Delta v - \frac{1}{3}(v + Z)^3 + (v + Z) = \Delta v - \frac{1}{3}(v^3 + 3v^2 Z + 3v Z^2 + Z^3) + (v+Z)\\
    v_0 &= X^0
  \end{split}
\end{align}
equation. If we assume for the initial datum $X^0 \in \mathcal{C}^\alpha~(\alpha \in (1, 2))$, and if we considered now $(Z, Z^1, Z^2)$ as arbitrary processes (ie, the superscripts denoting indices, and not exponentiation) with $Z^i \in {C}(\RR_+, \mathcal{C}^{\alpha-2})$, then we get from setting up a Picard iteration, that there exists a random time $T^\star$ depending on $(Z, Z^2, Z^3)$ and a unique solution $v$ depending continuously on $(X^0, Z, Z^1, Z^2)$ \cite[Theorem 4.10.]{perkowski2024stochaIV}.

Since $Z_\epsilon$ is a smooth function, we can actually construct its powers and apply the above result, then take the $\epsilon \to 0$ limit in the hope of obtaining a solution $v$. Unfortunately $Z_\epsilon^2$ diverges as $\epsilon \to 0$, thus we cannot exploit the continuity of the solution operator from above. To fix this, one replaces the $n^\text{th}$ power with the $n^\text{th}$ Hermite polynomial as
\begin{align}
  Z_\epsilon^{:n:}(t, x) \DefiningEquality H_n(Z_\epsilon(t, x), \mathfrak{c}_\epsilon(t))\,
\end{align}
where $H_0(x, t) \equiv 1$, $H_{n}(x, t) = x H_{n-1}(x, t) - t \partial_x H_{n-1}(x, t)~(n \ge 1)$ and
\begin{align*}
  \mathfrak{c}_\epsilon(t) = \Exp{Z_\epsilon(t, 0)^2}\,.
\end{align*}
One can show the existence of the limits in $\epsilon \to 0$:
\begin{theorem}[Proposition 3.1. in \cite{mourrat2015convergencetwodimensionaldynamicisingkac}]
  For every $T > 0$ and every $\nu > 0$, the stochastic processes $Z_\epsilon$ and $Z_\epsilon^{:n:}$ for $n \ge 2$ converge almost surely and in every stochastic $L^p$ space with respect to the metric of $\mathcal{C}([0, T], \mathcal{C}^{-\nu})$. We denote the limiting processes by $Z$ and $Z^{:n:}$.
\end{theorem}
In the above proof it is crucial that we can represent $Z_\epsilon^{:n:}(x, t)$ as an object in the $n^\text{th}$ homogenous Wiener-Itô chaos, meaning we can write $Z_\epsilon^{:n:}(t, x)$ as an iterated stochastic integral of a symmetric deterministic function against a Gaussian noise. Guassianity of the noise let us bound higher moments of $Z_\epsilon^{:n:}(t, x)$ by $\Exp{Z_\epsilon^{:n:}(t, x)^2}$, which in turn leads to bounds on $\Exp{\norm{Z_\epsilon^{:n:}(t, \Placeholder)}^p_{\mathcal{C}^{-\nu}}}$ uniform in $\epsilon$ to guarantee tightness, and bounds on $\Exp{\norm{Z_\epsilon^{:n:}(t, \Placeholder) - Z_\epsilon^{:n:}(s, \Placeholder)}^p_{\mathcal{C}^{-\nu}}}$ to get continuity in time from Kolmogorov's continuity criteria.

For the convergence of the discretized model, it will be slightly more convenient \cite[p.14]{mourrat2015convergencetwodimensionaldynamicisingkac} to set the initial datum to $v_0 = 0$, thus a shift of the Wick products of the stochastic convolution is necessary. For $Y(t) \DefiningEquality P_t X^0$, let us define
\begin{align}
  \label{eq:z_tilde_redefinition}
  \begin{split}
    \tilde{Z}(t, \Placeholder) &= Y(t, \Placeholder) + Z(t, \Placeholder)\\
    \tilde{Z}^{:2:}(t, \Placeholder) &= Z^{:2:}(t, \Placeholder) + 2Y(t, \Placeholder) Z(t, \Placeholder) + Y(t, \Placeholder)^2\\
    \tilde{Z}^{:3:}(t, \Placeholder) &= Z^{:3:}(t, \Placeholder) + 3 Y(t, \Placeholder) Z(t, \Placeholder)^{:2:} + 3Y(t, \Placeholder)^2 Z(t, \Placeholder) + Y(t, \Placeholder)^3\,.
  \end{split}
\end{align}
Then for $A(t) \DefiningEquality A + \lim_{\epsilon \to 0} (\mathfrak{c}_\epsilon - \mathfrak{c}_\epsilon(t))$, the equation
\begin{align}
  \label{eq:new_eq_in_v}
  \partial_t v &= \Delta v - \frac{1}{3}(v^3 + 3 \tilde{Z}v^2 + 3 \tilde{Z}^2 v + \tilde{Z}^3) + A(t) (\tilde{Z} + v)\\
  v(0, \Placeholder) &= 0
\end{align}
has a unique solution up until some random time $T^\star$, and the solution is \say{stable under approximation of the functions $Z_\epsilon$, $Z_\epsilon^{:2:}$ and $Z_\epsilon^{:3:}$ in $\mathcal{C}([0, \infty), \mathcal{C}^{-\nu}$} \cite{mourrat2015convergencetwodimensionaldynamicisingkac}. From \cite{mourrat2017global} we have moreover for a fixed initial datum and any $T>0$
\begin{theorem}
  For $\nu > 0$ small enough, fix an initial datum $X^0 \in \mathcal{C}^{-\nu}$. For $(Z, Z^{:2}, Z^{:3:}) \in (L^\infty([0, T], \mathcal{C}^{-\nu}))^3$, let $(\tilde{Z}, {\tilde{Z}^{:2:}}, \tilde{Z}^{:3:})$ be defined as in \eqref{eq:z_tilde_redefinition}. Let $\mathcal{S}_T(Z, Z^{:2:}, Z^{:3:})$ denote the solution $v$ on $[0, T]$ of the PDE \eqref{eq:new_eq_in_v}. Then for any $\kappa > 0$, the mapping $\mathcal{S}_T$ is Lipschitz continuous on bounded sets from $(L^\infty([0, T], \mathcal{C}^{-\nu}))^3$ to $\mathcal{C}([0, T], \mathcal{C}^{2 - \nu -\kappa}(\TT^2))$.
\end{theorem}

% \begin{itemize}
%   \item hontestly, I should maybe just handwave it, and state proposition 3.2, saying that a continuous solution operator exists.
%   % \item linearized solution $\tilde{X}$ lies in $\mathcal{C}^-$, so no way to interpret $\tilde{X}^3$ consistently, and no hope that the solution of the non-linear equation is any more regular
%   % \begin{itemize}
%   %   \item Perkowski had a slightly different argument, claiming that the solution is not better than the stochastic convolution, but I think it's pretty much the same
%   %   \item on the other hand if we spatially regularized the white noise by $$W_\epsilon(t, x) = \frac{1}{4}\sum_{\lvert k \rvert < \epsilon^{-1}} e^{i \pi k \cdot x}\hat{W}(k, t) = \mathcal{F}^{-1}_{\mathbb{T}^2}(\varphi_\epsilon \mathcal{F}_{\mathbb{T}^2}W(t, \cdot))(x)$$then the solution $X_\epsilon$ of $$dX_\epsilon = (\delta X_\epsilon - \frac{1}{3} X^3_\epsilon + A X_\epsilon) dt + \sqrt{2} dW_\epsilon$$converges in probability to $0$
%   %   % \item for the record, $Z_\epsilon(t, \cdot) = \int_0^t P_{t-s} dW_\epsilon(s, \cdot)$ is the same as localizing the heat kernel and convolving it with $dW$, which is again the same as spatially localizing the stochastic convolution (think about the Fourier cutoff projector as a self-adjoint linear operator, thus we can pull it in, by considering how the stochastic convolution acts on test functions)
%   %   % \item in order to obtain a nontrivial limit, we have to adjust the above approximation by adding a linear term with logarithmically diverging coefficient $\mathfrak{c}_\epsilon = \sum_{0 < |k| < \epsilon^{-1}}\frac{1}{4\pi^2 | k|^2}$.
%   % \end{itemize}
%   % \item Consider the mild solution $Z_\epsilon(t, \cdot) = \int_0^t P_{t-s} dW_\epsilon(s, \cdot)$ of the linearized equation. We can define $Z_\epsilon^n$ but this won't converge for $n \ge 2$. Instead of that we consider $Z^{:n:}_\epsilon(t, \cdot) = H_n(Z(t, \cdot), \mathfrak{c}_\epsilon)$ which will converge as $\epsilon \to 0$ with 
% \end{itemize}

% \begin{itemize}
  % \item variant of the ferromagnetic Ising model
  % \begin{itemize}
  %   \item Ising-Kac: not only closest neighborhood interactions, but in a small radius of $\gamma^{-1}$
  %   \item using Glauber dynamics for the jump probabilities
  %   \item "random fluctuations of a \[...\] magnetisation field $X_\gamma$ in the limit $\gamma \to 0$, for inverse temperature close to the critical temperature of the mean field model" 
  %   \item ~"under suitable assumptions [...] these fields converge in law to the solution of the $\Phi^4_2$ equation"
  % \end{itemize}
  % \item $\Phi^4_2$ is ill defined, solution theory is more "intricate" (p1) (than that of $\Phi^4_1$)
  % \begin{itemize}
  %   \item solution is at best as good as the stochastic convolution term, no "consistent" definition of the term $X^3$,
  %   \item renormalization needed, so instead of $$\partial_t X(t, x) = \Delta X(t, x) - \frac{1}{3} X^3(t, x) + A X(t, x) + \sqrt{2}\xi(t, x)$$we formally solve $$\partial_t X(t, x) = \Delta X(t, x) - \frac{1}{3} (X^3(t, x) - 3 \infty \times X(t, x))+ A X(t, x) + \sqrt{2}\xi(t, x)$$(for the solution theory see Perkowski, or directly da Prato-Debussche)
  %   \item other solution theory, which allows to solve much more singular SPDEs, motivation: "to show that fluctuations of non-linear particle systems are governed by such an equation". 
  % \end{itemize}
  % \item interesting feature of the result: "it gives a natural interpretation for the infinite renormalisation constant as a shift of critical temperature away from its mean field value"
  % \item use of the Kac-type interactions prevents the model from converging to the continuous Ising model
% \end{itemize}
% \chapter{Setting and main result}
% \begin{itemize}
%   % \item microscopic system
%   % \begin{itemize}
%   %   \item the setting on $\Lambda_N = \mathbb{Z}^2 / (2N + 1)\mathbb{Z}^2$ is quite clear
%   %   % \begin{itemize}
%   %   %   \item except some constraints on the kernel:
%   %   %   \begin{itemize}
%   %   %     \item supported on a ball of radius 3 (I guess to make it interesting enough?)
%   %   %     \item why do we have $\mathfrak{K}(0) = 0$  (to avoid self interactions? if we didn't have this, then the mean field would be a constant higher or lower, no?)
%   %   %   \end{itemize}
%   %   % \end{itemize}
%   %   \item locally averaged field $\to$ Hamiltonian $\to$ Gibbs measure $\to$ Glauber dynamics $\to$ $(\sigma_t)_{t\ge 0}$ pure jump Markov process on $\Sigma_N$ describing the evolution of the spin configurations, and the corresponding $h_\gamma(\sigma)$ local mean field
%   %   % \item (Le Gall): $h_\gamma(t, k) = h_\gamma(0, k) + \int_0^t \mathcal{L} h_\gamma(s, k)\,ds + m_\gamma(t, k)$, where $(m_\gamma(t, k))_{t \ge 0}$ is a martingale for all $k \in \Lambda_N$. The [[predictable quadratic covariation]] of the martingale are given in $(2.10)$.
%   %   % \begin{itemize}
%   %   %   \item note: if we discretized the time and we interpreted $\mathcal{L}$ as $P-I$ operator, then it's clear why $m$ is a martingale.
%   %   % \end{itemize}
%   % \end{itemize}
%   % \item macroscopic coordinates:
%   % \end{itemize}
%   % \item extension of functions given on the macroscopic coordinates to the whole $\mathbb{T}^2$:
%   % \begin{itemize}
%   %   % \item discrete Fourier transform on discrete coordinates, then inverse Fourier transform on the whole $\mathbb{T}^2$ $\textcolor{red}{\text{Q: why do we get something real valued here}}$   
%   %   % \begin{itemize}
%   %   %   \item the extension will coincide with the original function on the discrete points
%   %   %   \item extension is compatible with known results: well behavedness with respect to convolution and Parseval.
%   %   % \end{itemize}
%   % \end{itemize}
%   \item main result:
% \end{itemize}

\chapter{Bounds for the linearized system}
For each $x \in \Lambda_\epsilon$, we can consider the evolution equation of the discrete system as a differential equation, whose mild formulation reads as 
\begin{align*}
  X_\gamma(t, x) = P^\gamma_t X^0_\gamma &+ \int_{0}^{t}P^\gamma_{t-r} \Convolve[\epsilon]{K_\gamma}{\left(-\frac{\beta^3}{3}X^3_\gamma(r, x) + (\mathfrak{c}_\gamma + A) X_\gamma(r, x) + E_\gamma(r, x)\right)\,dr}\\
  &+\int_{0=r}^{t}P^\gamma_{t-r}\,dM_\gamma(r, x)\,,
\end{align*}
where $\int_0^t \DefiningEquality \int_{(0, t]}$ and $P^\gamma_t \DefiningEquality e^{\Delta_\gamma t}$ is the semigroup generated by $\Delta_\gamma$, which acts on functions $Y: \Lambda_\epsilon \to \RR$ through convolution with a kernel, also denoted by $P^\gamma_t$.

Let us denote $Z_\gamma(t, x) = \int_{r = 0}^t P^\gamma_{t-r} \,dM_\gamma(r, x)$, which is the solution of the linearized evolution equation
\begin{align*}
  dZ_\gamma(t, x) &= \Delta_\gamma Z_\gamma(t, x) dt + dM_\gamma(t, x)\\
  Z_\gamma(0, x) &= 0 \,.
\end{align*}

Similarly to the case of the $\Phi^4_2$ equation, we define iterated integrals against the noise term $(M(t, x))_{t \ge 0}$: for $x \in \Lambda_\epsilon$ and $t \ge 0$, let 
\begin{align*}
  R^{:1:}_{\gamma, t}(s, x) &\DefiningEquality R_{\gamma, t}(s, x) \DefiningEquality \int_{r = 0}^s P^\gamma_{t-r} \,dM_\gamma(r, x)\,\\
  R^{:n:}_{\gamma, t}(s, x) &\DefiningEquality n \int_{r = 0}^s R^{:n-1:}_{\gamma, t}(r^{-}, x)\,dR_{\gamma, t}(r, x)~(n\ge2)\,,
\end{align*}
and moreover $Z^{:n:}_\gamma(t, x) := R^{:n:}_{\gamma, t}(t, x)$\footnote{For $n \ge 2$  we do not use the $\Ext$ operator for the continuous extension of $R^{:n:}_{\gamma, t}(t, \cdot)$ to a $\TT^2 \to \RR$ function, but we take the inverse Fourier transform of $\hat{R}^{:n:}_{\gamma, t}(t, \cdot) \DefiningEquality n \int_{r = 0}^s \hat{R}^{:n-1:}_{\gamma, t}(r^-, x)\,d\hat{R}_{\gamma, t}(r, x)$, since according to the authors, \say{products are not well captured by} extending by $\Ext$.}. In this section the goal is to obtain uniform bounds in Besov norms on the terms $R^{:n:}_{\gamma, t}$ and $Z^{:n:}_\gamma$, which we later use to prove the convergence of $Z^{:n:}_\gamma$ to a Hermite polynomial and the tightness of a family of distributions.

Contrary to the $\Phi^4_2$ case, we are not integrating against a Gaussian noise anymore, and furthermore $R^{:n:}_{\gamma, t}(\cdot, x)$ is discontinuous. Thus, instead of exploiting the Gaussian hypercontractivity, the authors introduce a general bound in \cite[Lemma 4.1.]{mourrat2015convergencetwodimensionaldynamicisingkac} for iterated integrals against the $(M_\gamma(\cdot, x))_{t \ge 0}$ martingales to control the higher moments, which will in particular be used in order to obtain bounds on $R^{:n:}_{\gamma, t}$ and $Z^{:n:}_\gamma$. To work around the above mentioned issues, they use a version of BDG, after controlling the errors caused by the discontinuities in the jump process, which leads to
\begin{proposition}[{\cite[Proposition 4.2.]{mourrat2015convergencetwodimensionaldynamicisingkac}}]
  \label{prop:bounds_proposition_4.2}
  There exists a constant $\gamma_0 > 0$ such that the following holds. For every $n \in \NN$, $p \ge 1$, $\nu > 0$, $T > 0$, $0\le \lambda \le \frac{1}{2}$ and $0 < \kappa \le 1$, there exists a constant $C = C(n, p, \nu, T, \lambda, \kappa)$ such that for every $0 \le s \le t \le T$ and $0 < \gamma < \gamma_0$,
  \begin{align*}
    \Exp{\sup_{0\le r \le t} \norm{R^{:n:}_{\gamma, t}(r, \Placeholder)}^p_{\mathcal{C}^{-\nu-2\lambda}}} &\le C t^{\lambda p} + C \gamma^{p(1-\kappa)}\,,\\
    \Exp{\sup_{0\le r \le t} \norm{R^{:n:}_{\gamma, t}(r, \Placeholder) - R^{:n:}_{\gamma, s}(r \land s, \Placeholder)}^p_{\mathcal{C}^{-\nu-2\lambda}}} &\le C \abs{t -s}^{\lambda p} + C \gamma^{p(1-\kappa)}\,,\\
    \Exp{\sup_{0\le r \le t} \norm{R^{:n:}_{\gamma, t}(r, \Placeholder) - R^{:n:}_{\gamma, t}(r \land s, \Placeholder)}^p_{\mathcal{C}^{-\nu-2\lambda}}} &\le C \abs{t -s}^{\lambda p} + C \gamma^{p(1-\kappa)}\,,
  \end{align*}
\end{proposition}
As remarked in \cite[Remark 4.3.]{mourrat2015convergencetwodimensionaldynamicisingkac}, the previous proposition implies under the same conditions the weaker
\begin{align*}
      \Exp{ \norm{Z^{:n:}_{\gamma}(t, \Placeholder)}^p_{\mathcal{C}^{-\nu-2\lambda}}} &\le C t^{\lambda p} + C \gamma^{p(1-\kappa)}\,,\\
    \Exp{\norm{Z^{:n:}_{\gamma}(t, \Placeholder) - Z^{:n:}_{\gamma}(s, \Placeholder)}^p_{\mathcal{C}^{-\nu-2\lambda}}} &\le C \abs{t -s}^{\lambda p} + C \gamma^{p(1-\kappa)}\,,\\
    \Exp{\norm{Z^{:n:}_{\gamma}(r, \Placeholder) - R^{:n:}_{\gamma, t}(s, \Placeholder)}^p_{\mathcal{C}^{-\nu-2\lambda}}} &\le C \abs{t -s}^{\lambda p} + C \gamma^{p(1-\kappa)}\,,
\end{align*}
bounds, which are going to be used later to prove the tightness of the $\left\{Z^{:n:}_\gamma, \gamma \in (0, \frac{1}{3})\right\}$ family, and the joint convergence of $(Z^{:1:}_{\gamma, \mathfrak{m}}, \ldots, Z^{:n:}_{\gamma, \mathfrak{m}})$ to $(Z^{:1:}, \ldots, Z^{:n:})$ in law with respect to the topology of $\mathcal{D}(\RR_+, \mathcal{C}^{-\nu})^n$, where $Z^{:n:}_{\gamma, \mathfrak{m}}$ will be defined later as a process identical to $Z^{:n:}_{\gamma}$ up to a certain stopping time, and then extended differently.

\chapter{Tightness for the linearized system}
In a topological space we call a set $A$ relatively compact, if its closure $\Closure{A}$ is compact. From Prohorov's Theorem \cite[Theorem 5.1. and Theorem 5.2.]{billingsley2013convergence} a family of measures on a Polish space is relatively compact with respect to weak convergence if and only if it is tight. In particular, since we work with a non-standard definition of the Besov space $\mathcal{C}^{-\nu}$, namely as the closure of $C^\infty\left(\TT^2\right)$ under the norm $\norm{\Placeholder}_{\mathcal{C}^{-\nu}}$, we have that $\mathcal{C}^{-\nu}$ is a Polish space \cite[p70]{mourrat2015convergencetwodimensionaldynamicisingkac}. This implies that the Skorokhod space $\mathcal{D}(\RR_+, \mathcal{C}^{-\nu})$ is also a Polish space \cite[Theorem 12.2.]{billingsley2013convergence}. In particular, if the laws of $\mathcal{Z} = \left\{Z^{:n:}_\gamma, \gamma \in (0, \frac{1}{3})\right\}$ are tight, then $Z^{:n:}_\gamma \DConv Z^{:n:}$ as $\gamma \to 0$ if and only if for every sequence $(\gamma_n)_{n \in \NN}$ with $\gamma_n \to 0^+$ the subsequential limits $Z^{:n:}_{\gamma_n}$ exists and equal to $Z^{:n:}$.

Similarly to the case of the $\Phi^4_2$ equation, $Z^{:n:}_\gamma$ can be (approximately) written as a Hermite polynomial. The $\gamma_0$ constant in the following proposition is from \cite[Lemma 8.2]{mourrat2015convergencetwodimensionaldynamicisingkac} regarding bounds on the Fourier coefficients of $K_\gamma$ and its derivatives, which are uniform in $\gamma < \gamma_0$.

\begin{proposition}[{\cite[Proposition 5.3]{mourrat2015convergencetwodimensionaldynamicisingkac}}]
  For the above $\gamma_0$ and for any $n\in\NN$, $\kappa >0$ and $1 \le p < \infty$, there exists $C = C(n, p, t, \kappa) > 0$ such that for every $0 < \gamma < \gamma_0$\,
  \begin{align*}
    \left(\Exp{\sup_{x \in \TT^2} \sup_{0 \le s \le t} \abs{E^{:n:}_{\gamma, t}(s, x)}^p}\right)^{1/p} \le C \gamma^{1 - \kappa}\,
  \end{align*}
  where $E^{:n:}_{\gamma, t}(s, x) = H_n(R_{\gamma, t}(s, x), \Bracket{R_{\gamma, t}(\Placeholder, x)}_s) - R^{:n:}_{\gamma, t}(s, x)$ and $\Bracket{M}_t$ is the bracket process defind for any square-integrable càdlàg martingale as $\Bracket{M}_t = M^2(t) - 2 \int_{0}^{t}M^{s^{-}} dM(s)$.
\end{proposition}
This approximate representation of $Z_\gamma^{:n:}$ as Hermite polynomials used in 
% \begin{itemize}
%   \item Discussion of the terms $Z_\gamma^{:n:}$ and $R_{\gamma, t}^{:n:}$ is continued. After having obtained bounds on the goodness of the approximation in Prop 4.2, we give additional bounds related to the [[predictable quadratic variation]]s (for $M$ [[càdlàg]] $L^2$ martingale it's the unique $\langle M \rangle$ making $M^2 -  \langle M \rangle$ into a martingale) and the [[bracket process]] $[M]_t = M^2_t - 2\int_0^t M(s^-)dM(s)$, namely
%   \begin{itemize}
%     \item a bound on their differences
%     \item a bound on the $L^p$ norm of the $\sup_{x \in \Lambda_\epsilon} [R_{\gamma, t}(\cdot, x)]$ 
%   \end{itemize}
%   \item we define now $E^{:n:}_{\gamma, t}(s, x) = H_n(R_{\gamma, t}(s, x), [R_{\gamma, t}(\cdot, x)]_s) - R^{:n:}_{\gamma, t}(s, x)~(x\in \mathbb{T}^2)$ where $[R_{\gamma, t}(\cdot, x)]_s$ is the trig extension of $[R_{\gamma, t}(\cdot, x)]_s$. The claim of Proposition 5.3 is that we can approximate $R^{:n:}_{\gamma, t}(s, x)$ as a Hermite polynomial with the following error bound:$$\mathbb{E}[\sup_{x\in\mathbb{T}^2}\sup_{0\le s \le t} \lvert E^{:n:}_{\gamma, t}(s, x)\rvert^p]^{1/p} \le C \gamma^{1 - \kappa}$$
%   \begin{itemize}
%     \item does this imply that for some $x$ the minimum error is not necessarily obtained for $s = t$?
%     \item for $x\in \Lambda_{\epsilon}$ is the error $0$? I guess not, since then from Lemma A.6 the whole error would be 0
%   \end{itemize}
% \end{itemize}


\begin{proposition}
  \label{prop:Z_is_tight}
  For any fixed $n\in \mathbb{N}$ and any $\nu > 0$, the family $\left\{Z^{:n:}_{\gamma}, \gamma \in (0, 1/3) \right\}$ is tight on $\mathcal{D}(\mathbb{R}_+, \mathcal{C}^{-\nu})$. Any weak limit is supported on $\mathcal{C}(\mathbb{R}_+, \mathcal{C}^{-\nu})$. Furthermore, for any $p \ge 1$ and $T > 0$, we have 
  \begin{align}
    \label{eq:uniform_bound_stuff}
    \sup_{\gamma \in (0, 1/3)} \mathbb{E}\left[ \sup_{0 \le t \le T} \lVert Z^{:n:}_\gamma(t, \cdot)\rVert^p_{\mathcal{C}^{-\nu}} \right] < \infty\,.
  \end{align}
\end{proposition}
\begin{proof}
  Since we are only interested in what is happening as $\gamma$ goes to $0$, we can further restrict $\gamma$ to $(0, \gamma_0)$ for $\gamma_0$ from \autoref{prop:bounds_proposition_4.2}. Moreover, since for the tightness of the law of some processes in $\mathcal{D}(\RR_+,\mathcal{C}^{-\nu})$ it is sufficient to prove that the law of the processes restricted to all compact time intervals are tight \cite{mourrat2015convergencetwodimensionaldynamicisingkac}. Let $T > 0$ and we show tightness on $\mathcal{D}([0, T], \mathcal{C}^{-\nu}]$.

  Let $m\in\NN$ to be fixed later. From the estimates \autoref{prop:bounds_proposition_4.2} we get for all $s \neq t \in \gamma^m \NO$, $p\ge 1$ $\nu^\prime > 0$, $\lambda \le \frac{1}{2m}$ and $n \in \NN$ for some $C = C(n, p, \nu^\prime, T, \lambda)$ constant 
  \begin{align}
    \label{eq:almost_kolmogorov_criteria}
    \Exp{\norm{Z^{:n:}_\gamma(t, \cdot) - Z^{:n:}_\gamma(s, \cdot)}^p_{C^{-\nu^\prime - 2\lambda}}} \le C \left(\abs{t - s}^\lambda + \gamma^{\frac{1}{2}}\right)^p \le C \abs{t - s}^{\lambda p}\,.
  \end{align}
  Note, that for the second inequality $\abs{t - s} \ge \gamma^m$ was crucial, thus we cannot use a Kolmogorov style criteria directly. We construct instead a continuous linear interpolation $\tilde{Z}^{:n:}_\gamma$ of $Z^{:n:}_\gamma$ such that they coincide on discrete times $\gamma^m \NO$. We have now
  \begin{align}
    \Exp{\norm{\tilde{Z}^{:n:}_\gamma(t, \cdot) - \tilde{Z}^{:n:}_\gamma(s, \cdot)}^p_{C^{-\nu^\prime - 2\lambda}}} \le C \abs{t - s}^{\lambda p}\,.    
  \end{align}
  for all $s, t \in [0, T]$, and thus from
  \begin{corollary}[Kolmogorov Tightness Criterion, {\cite[Corollary 14.9]{kallenberg2013foundations}}]
    Let $X^1, X^2, \ldots$ be continuous processes on $R^d$ with values in a separable, complete metric space $(S, \rho)$. Assume that $(X_0^n)$ is tight in $S$ and that for some constants $a, b > 0$
    \begin{align*}
      \Exp{\rho(X^n_s, X^n_t)^a} \lesssim \abs{s - t}^{d + b}\,, \quad s, t \in \RR^d, n \in \NN\,
    \end{align*}
    uniformly in $n$. Then $(X^n)$ is tight in $\mathcal{C}(\RR^d, S)$ and for every $c \in (0, b/a)$ the limiting processes are a.s. locally Hölder continous with exponent $c$.
  \end{corollary}
  we get immediately for $\hat{\mathcal{Z}} \DefiningEquality \left\{\hat{Z}^{:n:}_{\gamma}, \gamma \in (0, 1/3)\right\}$ tightness, continuity of the subsequential limits, and the bound \eqref{eq:uniform_bound_stuff} from the almost sure Hölder continuity. The remaining of the proof is about proving for any $\kappa > 0$ and $p\ge1$ the
  \begin{align*}
    \Exp{\sup_{0 \le t \le T} \sup_{x \in \TT^2} \abs{ \hat{Z}^{:n:}_\gamma(t, x) - Z^{:n:}_\gamma(t, x)}^p} \le C(n, p, T, \kappa) \gamma^{(1 - \kappa) p}
  \end{align*}
  bound which lets us transfer the results obtained for the family $\hat{\mathcal{Z}}$ to $\mathcal{Z}$.
\end{proof}

\chapter{Convergence in law of the linearised system}
After showing tightness of $\mathcal{Z} = \left\{Z^{:n:}_\gamma, \gamma\in(0, 1/3)\right\}$ it still remains to show the convergence of $Z^{:n:}_\gamma$ as $\gamma \to 0$. In this section we show a partial result, namely the convergence of $Z^{:n:}_{\gamma, \mathfrak{m}}$ to $Z$ (the stochastic convolution in the $\Phi^4_2$ equation). This $Z^{:n:}_{\gamma, \mathfrak{m}}$ is identical to $Z^{:n:}_{\gamma}$ up until a random time $\tau_{\gamma, \mathfrak{m}}$, beyond which we extend it by modifying first the dynamics of $(\sigma(t, \cdot))_{t \ge 0}$, and equating $Z^{:n:}_{\gamma, \mathfrak{m}}$ to the stochastic convolution from mild formulation of the evolution equation of this new Markov chain.

Thus for a fixed $\nu \in \left(0, \frac{1}{2}\right)$, and $\mathfrak{m} > 1$ and $0 < \gamma < 1$ arbitrary, let us define
\begin{align}
  \tau_{\gamma, \mathfrak{m}} \DefiningEquality \inf \left\{t \ge 0: \norm{X_\gamma(t, \Placeholder)}_{\mathcal{C}^{-\nu}} \ge \mathfrak{m}\right\}\,.
\end{align}
and define a new jump process for $k \in \Lambda_N$ as 
\begin{align*}
  \sigma_{\gamma, \mathfrak{m}} \DefiningEquality \begin{cases}
    \sigma(t, k)&\text{if } t < \frac{\tau_{\gamma, \mathfrak{m}}}{\alpha}\\
    \sigma^\prime(t, k)&\text{otherwise}
  \end{cases}\,,
\end{align*}
where $\sigma^\prime_{\gamma, \mathfrak{m}}(t, k)$ is a different Markov process, where in the infinitesimal generator we replaced the jump rates with $\frac{1}{2}$. We can thus define $h_{\gamma, \mathfrak{m}}(t, k) = \Convolve{\sigma_{\gamma,\mathfrak{m}}}{\kappa_\gamma}(k)~(t \ge 0, k \in \Lambda_N)$ and \begin{align*}
  m_{\gamma, \mathfrak{m}}(t, k) \DefiningEquality h_{\gamma, \mathfrak{m}}(t, k) - h_{\gamma, \mathfrak{m}}(0, k) - \int_{0}^{t} \mathcal{L}^s_{\gamma, \mathfrak{m}} h_{\gamma, \mathfrak{m}}(s, k)\,ds\,
\end{align*}
where $\mathcal{L}^s_{\gamma, \mathfrak{m}}$ is the infinitesimal generator defined similary as before, but with jump rates $$c^s_{\gamma, \mathfrak{m}} = \begin{cases}
  c_\gamma&\text{if }s < \frac{\tau_{\gamma, \mathfrak{m}}}{\alpha}\\
  \frac{1}{2}&\text{otherwise}
\end{cases}.$$

\begin{remark}
  \label{remark:all_previous_results_hold}
  For every previously defined process we can define the corresponding modified version, indexed by $_{\gamma, \mathfrak{m}}$ instead of $_\gamma$, and all previous results and estimates still hold, since they are independent of the jump rates (besides requiring them to be $\le 1$) \cite[p39]{mourrat2015convergencetwodimensionaldynamicisingkac}.
\end{remark}

Even though we have no control on $X_\gamma$ yet, such a construction was necessary, since later some error bounds will depend on $\norm{X_\gamma(t, \Placeholder)}_{\mathcal{C}^{-\nu}}$, and we want to bound the corresponding terms uniformly by $\mathfrak{m}$.

\begin{theorem}[Convergence of $Z_{\gamma,\mathfrak{m}}$, {\cite[Theorem 6.1]{mourrat2015convergencetwodimensionaldynamicisingkac}}]
  Let $\nu \in (0, 1/2)$ and $\mathfrak{m} > 1$. As $\gamma$ tends to $0$, the processes $Z_{\gamma, \mathfrak{m}}$ converge in law to $Z$ with respect to the Skorokhod topology on $\mathcal{D}(\RR_+, \mathcal{C}^{-\nu})$, where $Z$ is the stochastic convolution from the $\Phi^4_2$ equation.
\end{theorem}
\begin{proof}
  Since from \autoref{prop:Z_is_tight} the family $\mathcal{Z} \DefiningEquality \left\{Z_\gamma, \gamma \in (0, \frac{1}{3})\right\}$ was tight, from \autoref{remark:all_previous_results_hold} we have that $\mathcal{Z}_\mathfrak{m} \DefiningEquality \left\{Z_{\gamma, \mathfrak{m}}, \gamma \in (0, \frac{1}{3})\right\}$ is also tight.

  Since $\mathcal{Z}_\mathfrak{m}$ is tight, for any $\gamma_n \to 0$ let $\overline{Z}$ denote the subsequential limit of $Z_{\gamma_{k_n}, \mathfrak{m}}$ as $n \to \infty$. We need to show, that $Z \DEquiv \overline{Z}$. For that, the idea is to use the following characterization of the solution of the stochastic heat equation:

  \begin{theorem}
    Let $\overline{Z}$ be a random process in $\mathcal{C}(\RR_+, \mathcal{S}^\prime(\TT^2))$. For every $\phi \in \mathcal{C}^\infty(\TT^2)$, define
    \begin{align*}
      \mathcal{M}_\phi(t) = (\overline{Z}(t), \phi) - (\overline{Z}(0), \phi) - \int_0^t(\overline{Z}(s), \Delta \phi)\,ds\,,
    \end{align*}
    where $(\overline{Z}(s), \phi)$ means the evaluation of $\overline{Z}$ against $\phi$, and
    \begin{align*}
      \Gamma_\phi(t) = \mathcal{M}_\phi^2(t) - 2 t \norm{\phi}^2_{L^2}\,.
    \end{align*}
    If for every $\phi$, the processes $(\mathcal{M}_\phi(t))_{t \ge 0}$ and $(\Gamma_\phi(t))_{t \ge 0}$ are local martingales, then $\overline{Z}$ has the same law as the solution $Z$ of the stochastic heat equation
    \begin{align*}
      \begin{cases}
        dZ = \Delta Z\,dt + \sqrt{2}\,dW\\
        Z(0, \cdot) = z_0
      \end{cases}
    \end{align*}
  \end{theorem}
  The remainder of the proof shows the validity of the above theorem for every $\phi \in \mathcal{C}^\infty(\TT^2)$ trigonometric polynomials, which is sufficient according to \cite[Remark C.4]{mourrat2015convergencetwodimensionaldynamicisingkac}
\end{proof}

As for the joint convergence of $(Z_{\gamma, \mathfrak{m}}^{:1:}, \ldots, Z_{\gamma, \mathfrak{m}}^{:n:})$ in law to $(Z^{:1:}, \ldots, Z^{:n:})$ with respect to the topology of $\mathcal{D}(\mathbb{R}_+, \mathcal{C}^{-\nu})^n$, we can first conclude that since $\mathcal{Z}^{:n:}_\mathfrak{m} = \left\{Z_{\gamma, \mathfrak{m}}^{:n:}, \gamma \in (0, 1/3)\right\}$ is tight, the family $\left\{(Z_{\gamma, \mathfrak{m}}^{:1:}, \ldots, Z_{\gamma, \mathfrak{m}}^{:n:}), \gamma \in (0, 1/3)\right\}$ is tight too with respect to the topolgy of $\mathcal{D}(\mathbb{R}_+, \mathcal{C}^{-\nu})^n$. Hence it suffices to verify the convergence of the finite dimensional distributions, which is equivalent to 
\begin{align*}
  \lim_{\gamma \to 0}\abs{\Exp{F(\bf{Z_\gamma(t_1), \ldots, Z_\gamma(t_K)})} - \Exp{F(\bf{Z(t_1), \ldots, Z(t_K)})}} = 0
\end{align*}
to hold for all $K \in \NN$, times $t_1 < t_2 < \ldots < t_K$ and $F: (\mathcal{C}^{-\nu})^{n \times K} \to \mathbb{R}$ bounded and uniformly continuous functions, where $\bf{Z}_\gamma = (Z^{:1:}_{\gamma, \mathfrak{m}}, \ldots, Z^{:n:}_{\gamma, \mathfrak{m}} )$ and $\bf{Z} = (Z^{:1:}, \ldots, Z^{:n:} )$, which is the strategy for the proof of 
\begin{theorem}[{\cite[Theorem 6.2]{mourrat2015convergencetwodimensionaldynamicisingkac}}]
  For every $\mathfrak{m} \in \NN$ and $n \in \NN$, the processes $(Z^{:1:}_{\gamma, \mathfrak{m}}, \ldots, Z^{:n:}_{\gamma, \mathfrak{m}} )$ converge (jointly) in law to $(Z^{:1:}, \ldots, Z^{:n:} )$ with respect to the topology of $\mathcal{D}(\RR_+, \mathcal{C}^{-\nu})^n$.
\end{theorem}

\chapter{Analysis of the non-linear equation}
We consider $\nu > 0$ small enough and fixed, and some initial data $X^0 \in \mathcal{C}^{-\nu}$ also fixed throughout the section. We denote $X \in \mathcal{C}(\mathbb{R}_+, \mathcal{C})$ the solution of the renormalized $\Phi^4_2$ equation as constructed in \fullref{chapter:solution_theory_of_phi_4_2}. $X_\gamma$ denotes the rescaled field and it satisfies the evolution equation given in mild form as
\begin{align*}
  \begin{split}
      X_\gamma(t, x) = P^\gamma_t X^0_\gamma &+ \int_{0}^{t} P^\gamma_{t-s} \Convolve[\epsilon]{K_\gamma}{\biggl(-\frac{\beta^3}{3}X^3_\gamma(s, \Placeholder) + (\mathfrak{c}_\gamma + A)X_\gamma(s, \Placeholder)\\ 
      &+E_\gamma(s, \Placeholder)\biggr)}\,ds + Z_\gamma(t, \Placeholder)
  \end{split}\,,
\end{align*}
which so far only holds on $\Lambda_\epsilon$, since the $\Ext$ operator does not commutes with cubing $X_\gamma$. To fix this, we introduce a new error term, basically by adjusting the term with the difference of $\Ext{(X^3_\gamma(s, \Placeholder))}$ and $\left(\Ext X_\gamma(s, \Placeholder)\right)^3$. With this new error term $\operatorname{Err}^{(1)}_\gamma(s, \Placeholder)$ the evolution equation on $\TT^2$ reads as 
  \begin{align}
    \label{eq:evolution_equation_with_new_errors}
    \begin{split}
        X_\gamma(t, x) = P^\gamma_t X^0_\gamma &+ \int_{0}^{t} P^\gamma_{t-s} \Convolve[\epsilon]{K_\gamma}{\biggl(-\frac{1}{3}X^3_\gamma(s, \Placeholder) + (\mathfrak{c}_\gamma(s, \Placeholder) + A(s))X_\gamma(s, \Placeholder)\\ 
        &+\operatorname{Err}^{(1)}(s, \Placeholder)\biggr)}\,ds + Z_\gamma(t, \Placeholder)
    \end{split}\,,
  \end{align}
where the precise bound on $\norm{\operatorname{Err}^{(1)}(s, \Placeholder)}_{L^\infty(\TT^2)}$ can be found in \cite[Lemma 7.2]{mourrat2015convergencetwodimensionaldynamicisingkac}.

Now for $\mathfrak{m} \ge 1$ we introduce a new process $X_{\gamma, \mathfrak{m}}(t, x)~(x \ge 0, x \in \TT^2)$ as the solution of \eqref{eq:evolution_equation_with_new_errors} with $Z_\gamma$ replaced by $Z_{\gamma, \mathfrak{m}}$ and $\operatorname{Err}^{(1)}$ replaced by
\begin{align*}
  \operatorname{Err}^{(1)}_\mathfrak{m}(s) \DefiningEquality \begin{cases}
    \operatorname{Err}^{(1)}(s)&\text{if }s \le \tau_{\gamma,\mathfrak{m}}\,,\\
    0&\text{otherwise}\,.
  \end{cases} 
\end{align*}
We get from a standard ODE argument the existence and uniqueness of this $X_{\gamma, \mathfrak{m}}$ \cite{mourrat2015convergencetwodimensionaldynamicisingkac}, which in particular coincides with $X_\gamma$ on the $\left\{t < \tau_{\gamma, \mathfrak{m}}\right\}$ event. The bound on $\norm{\operatorname{Err}^{(1)}(s, \Placeholder)}_{L^\infty(\TT^2)}$ depends (among other variables) on $\norm{X_\gamma(t)}_{\mathcal{C}^{-\nu}}$. Since $\tau_{\gamma, \mathfrak{m}}$ localizes $X_\gamma$ in the $\mathcal{C}^{-\nu}$ norm, we can make this bound independent from $\norm{X_\gamma(t)}_{\mathcal{C}^{-\nu}}$, and in particular the error term is $0$ on $\{t \ge \tau_{\lambda, \mathfrak{m}}\}$ by construction.

We construct another approximation of $X$. For $0 \le t \le T$ let us define
\begin{align*}
  \overline{X}_{\gamma, \mathfrak{m}}(t, \cdot) = P_t X^0 + Z_{\gamma, \mathfrak{m}}(t, \cdot) + \mathcal{S}_T(Z_{\gamma, \mathfrak{m}}, Z^{:2:}_{\gamma, \mathfrak{m}}, Z_{\gamma, \mathfrak{m}}^{:3:})(t, \cdot)
\end{align*}
where $\mathcal{S}_T$ is the solution operator of the $\Phi^4_2$ equation from \fullref{chapter:solution_theory_of_phi_4_2} for our fixed $X^0$ initial datum. As a reminder, we can write for $t \in [0, T]$ \begin{align*}
  X(t, \Placeholder) = P_t X^0(\Placeholder) + Z(t, \Placeholder) + \mathcal{S}_T(Z, Z^{:2:}, Z^{:3:})(t, \Placeholder)\,.
\end{align*} 
But since the solution operator is uniform countinuity on bounded sets and $(Z_{\gamma, \mathfrak{m}}, Z^{:2:}_{\gamma, \mathfrak{m}}, Z_{\gamma, \mathfrak{m}}^{:3:})$ converges in law jointly to $(Z, Z^{:2:}, Z^{:3:})$, we get that $\overline{X}_{\gamma, \mathfrak{m}} \DConv X$ with respect to $\mathcal{D}([0, T], \mathcal{C}^{-\nu})$ \cite[Lemma 7.2]{mourrat2015convergencetwodimensionaldynamicisingkac}.

The remainder of Section 7. in \cite{mourrat2015convergencetwodimensionaldynamicisingkac} is about constructing different bounds to show that for every fixed $\mathfrak{m} \ge 1$, $T > 0$ and bounded uniformly continuous function $F: \mathcal{D}([0, T], \mathcal{C}^{-\nu}) \to \RR$ we have
\begin{align*}
  \limsup_{\gamma \to 0} \Exp{\abs{F(\overline{X}_{\gamma, \mathfrak{m}} - F(X_{\gamma, \mathfrak{m}}))}} = 0\,,
\end{align*}
which together with the previous result implies the convergence in law of $X_{\gamma, \mathfrak{m}}$ to $X$ for every fixed $\mathfrak{m} \ge 1$ with respect to $\mathcal{D}([0, T], \mathcal{C}^{-\nu})$. What remains is to extend this convergence to with respect to $\mathcal{D}([0, T], \mathcal{C}^{-\nu})$ and to remove the stopping time $\tau_{\gamma, \mathfrak{m}}$ \say{by a soft argument} \cite{mourrat2015convergencetwodimensionaldynamicisingkac}, which ensures the converence of $X_\gamma$ to $X$ in law with respect to $\mathcal{D}([0, T], \mathcal{C}^{-\nu})$.
\medskip
% \newpage
% Bibliography can go on the same page with the appendix.
\printbibliography
\end{document}